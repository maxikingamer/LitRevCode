{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting semanticscholar\n",
      "  Downloading semanticscholar-0.4.1-py3-none-any.whl (17 kB)\n",
      "Collecting tenacity\n",
      "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\maxzi\\anaconda3\\lib\\site-packages (from semanticscholar) (2.25.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\maxzi\\anaconda3\\lib\\site-packages (from requests->semanticscholar) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\maxzi\\anaconda3\\lib\\site-packages (from requests->semanticscholar) (1.25.11)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\maxzi\\anaconda3\\lib\\site-packages (from requests->semanticscholar) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\maxzi\\anaconda3\\lib\\site-packages (from requests->semanticscholar) (2.9)\n",
      "Installing collected packages: tenacity, semanticscholar\n",
      "Successfully installed semanticscholar-0.4.1 tenacity-8.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install semanticscholar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semanticscholar import SemanticScholar\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_terms = [\"Machine-Generated Text Detection\",\n",
    "                \"Synthetic Text Detection\",\n",
    "                \"AI-Generated Text Detection\",\n",
    "                \"Computer-Generated Text Detection\"]\n",
    "\n",
    "secondary_terms = [\"Benchmark\",\n",
    "                   \"Costs\",\n",
    "                   \"Environment\",\n",
    "                   \"Ethics\",\n",
    "                   \"Evaluation\",\n",
    "                   \"Metric\",\n",
    "                   \"Model Architecture\",\n",
    "                   \"Risks\"]\n",
    "\n",
    "papers_df = pd.DataFrame(columns=[\"id\", \"title\", \"year\", \"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Machine-Generated Text Detection\": 3946 results.\n",
      "\"Machine-Generated Text Detection Benchmark\": 358 results.\n",
      "\"Machine-Generated Text Detection Costs\": 29 results.\n",
      "\"Machine-Generated Text Detection Environment\": 207 results.\n",
      "\"Machine-Generated Text Detection Ethics\": 3 results.\n",
      "\"Machine-Generated Text Detection Evaluation\": 1071 results.\n",
      "\"Machine-Generated Text Detection Metric\": 190 results.\n",
      "\"Machine-Generated Text Detection Model Architecture\": 227 results.\n",
      "\"Machine-Generated Text Detection Risks\": 128 results.\n",
      "\"Synthetic Text Detection\": 7899 results.\n",
      "\"Synthetic Text Detection Benchmark\": 710 results.\n",
      "\"Synthetic Text Detection Costs\": 177 results.\n",
      "\"Synthetic Text Detection Environment\": 650 results.\n",
      "\"Synthetic Text Detection Ethics\": 97 results.\n",
      "\"Synthetic Text Detection Evaluation\": 2162 results.\n",
      "\"Synthetic Text Detection Metric\": 525 results.\n",
      "\"Synthetic Text Detection Model Architecture\": 504 results.\n",
      "\"Synthetic Text Detection Risks\": 341 results.\n",
      "\"AI-Generated Text Detection\": 3945 results.\n",
      "\"AI-Generated Text Detection Benchmark\": 360 results.\n",
      "\"AI-Generated Text Detection Costs\": 31 results.\n",
      "\"AI-Generated Text Detection Environment\": 209 results.\n",
      "\"AI-Generated Text Detection Ethics\": 5 results.\n",
      "\"AI-Generated Text Detection Evaluation\": 1072 results.\n",
      "\"AI-Generated Text Detection Metric\": 192 results.\n",
      "\"AI-Generated Text Detection Model Architecture\": 227 results.\n",
      "\"AI-Generated Text Detection Risks\": 130 results.\n",
      "\"Computer-Generated Text Detection\": 3945 results.\n",
      "\"Computer-Generated Text Detection Benchmark\": 358 results.\n",
      "\"Computer-Generated Text Detection Costs\": 29 results.\n",
      "\"Computer-Generated Text Detection Environment\": 207 results.\n",
      "\"Computer-Generated Text Detection Ethics\": 3 results.\n",
      "\"Computer-Generated Text Detection Evaluation\": 1070 results.\n",
      "\"Computer-Generated Text Detection Metric\": 190 results.\n",
      "\"Computer-Generated Text Detection Model Architecture\": 227 results.\n",
      "\"Computer-Generated Text Detection Risks\": 128 results.\n"
     ]
    }
   ],
   "source": [
    "year = \"2019-\"\n",
    "fields_of_study = [\"Computer Science\"]\n",
    "open_access_pdf= True\n",
    "sch = SemanticScholar()\n",
    "papers_counts = []\n",
    "papers = []\n",
    "\n",
    "for anchor in anchor_terms:\n",
    "    results = sch.search_paper(query=anchor, year=year, fields_of_study=fields_of_study, open_access_pdf=open_access_pdf)\n",
    "    print(f'\"{anchor}\": {results.total} results.')\n",
    "    papers_counts.append(results.total)\n",
    "    for item in results:\n",
    "        papers.append(item)\n",
    "\n",
    "    for secondary in secondary_terms:\n",
    "        query = anchor + \" \" + secondary\n",
    "        results = sch.search_paper(query=query, year=year, fields_of_study=fields_of_study, open_access_pdf=open_access_pdf)\n",
    "        print(f'\"{query}\": {results.total} results.')\n",
    "        papers_counts.append(results.total)\n",
    "\n",
    "        for item in results:\n",
    "            papers.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'paperId': '2c206603bbc8bea9ad2d859719421ca99a23c77a', 'externalIds': {'DBLP': 'journals/corr/abs-2203-10209', 'ArXiv': '2203.10209', 'DOI': '10.1109/CVPR52688.2022.00455', 'CorpusId': 247594957}, 'corpusId': 247594957, 'publicationVenue': {'id': '768b87bb-8a18-4d9c-a161-4d483c776bcf', 'name': 'Computer Vision and Pattern Recognition', 'type': 'conference', 'alternate_names': ['CVPR', 'Comput Vis Pattern Recognit'], 'issn': '1063-6919', 'url': 'https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147', 'alternate_urls': ['https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition']}, 'url': 'https://www.semanticscholar.org/paper/2c206603bbc8bea9ad2d859719421ca99a23c77a', 'title': 'SwinTextSpotter: Scene Text Spotting via Better Synergy between Text Detection and Text Recognition', 'abstract': 'End-to-end scene text spotting has attracted great attention in recent years due to the success of excavating the intrinsic synergy of the scene text detection and recognition. However, recent state-of-the-art methods usually incorporate detection and recognition simply by sharing the backbone, which does not directly take advantage of the feature interaction between the two tasks. In this paper, we propose a new end-to-end scene text spotting framework termed SwinTextSpotter. Using a transformer encoder with dynamic head as the detector, we unify the two tasks with a novel Recognition Conversion mechanism to explicitly guide text localization through recognition loss. The straightforward design results in a concise framework that requires neither additional rectification module nor character-level annotation for the arbitrarily-shaped text. Qualitative and quantitative experiments on multi-oriented datasets RoIC13 and ICDAR 2015, arbitrarily-shaped datasets Total-Text and CTW1500, and multi-lingual datasets ReCTS (Chinese) and VinText (Viet-namese) demonstrate SwinTextSpotter significantly outperforms existing methods. Code is available at https://github.com/mxin262/SwinTextSpotter.', 'venue': 'Computer Vision and Pattern Recognition', 'year': 2022, 'referenceCount': 67, 'citationCount': 17, 'influentialCitationCount': 3, 'isOpenAccess': True, 'openAccessPdf': {'url': 'http://arxiv.org/pdf/2203.10209', 'status': 'GREEN'}, 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Conference'], 'publicationDate': '2022-03-19', 'journal': {'name': '2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)', 'pages': '4583-4593'}, 'authors': [{'authorId': '2156270580', 'name': 'Mingxin Huang'}, {'authorId': '2108353180', 'name': 'Yuliang Liu'}, {'authorId': '46216016', 'name': 'Zhenghao Peng'}, {'authorId': '9401586', 'name': 'Chongyu Liu'}, {'authorId': '1807606', 'name': 'Dahua Lin'}, {'authorId': '2901597', 'name': 'Shenggao Zhu'}, {'authorId': '1677643972', 'name': 'N. Yuan'}, {'authorId': '2053138829', 'name': 'Kai Ding'}, {'authorId': '144838978', 'name': 'Lianwen Jin'}]}\n",
      "31552\n",
      "31552\n"
     ]
    }
   ],
   "source": [
    "print(papers[0])\n",
    "print(len(papers))\n",
    "papers_set = set(papers)\n",
    "print(len(papers_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [x[\"paperId\"] for x in papers]\n",
    "titles = [x[\"title\"] for x in papers]\n",
    "years = [x[\"year\"] for x in papers]\n",
    "urls = [x[\"url\"] for x in papers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_df[\"id\"] = ids\n",
    "papers_df[\"title\"] = titles\n",
    "papers_df[\"year\"] = years\n",
    "papers_df[\"url\"] = urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2c206603bbc8bea9ad2d859719421ca99a23c77a</td>\n",
       "      <td>SwinTextSpotter: Scene Text Spotting via Bette...</td>\n",
       "      <td>2022</td>\n",
       "      <td>https://www.semanticscholar.org/paper/2c206603...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38c14553dbf3a308ada57dbea88aa890c6a2defb</td>\n",
       "      <td>Few Could Be Better Than All: Feature Sampling...</td>\n",
       "      <td>2022</td>\n",
       "      <td>https://www.semanticscholar.org/paper/38c14553...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d0f4407d7cbf5bb607f99e0a30fc7e311b486b60</td>\n",
       "      <td>Towards End-to-End Unified Scene Text Detectio...</td>\n",
       "      <td>2022</td>\n",
       "      <td>https://www.semanticscholar.org/paper/d0f4407d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00d124fab3e4895130f3563bb7e03b18b646a682</td>\n",
       "      <td>Kernel Proposal Network for Arbitrary Shape Te...</td>\n",
       "      <td>2022</td>\n",
       "      <td>https://www.semanticscholar.org/paper/00d124fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08b6f8cdaaa3d090f0ffab2c41fc1261a24d7b76</td>\n",
       "      <td>Fourier Contour Embedding for Arbitrary-Shaped...</td>\n",
       "      <td>2021</td>\n",
       "      <td>https://www.semanticscholar.org/paper/08b6f8cd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31547</th>\n",
       "      <td>6b84ba4f4a070de01b3638f76f62cf708aa776fa</td>\n",
       "      <td>Editorial: Designing a Protocol Adopting an Ar...</td>\n",
       "      <td>2021</td>\n",
       "      <td>https://www.semanticscholar.org/paper/6b84ba4f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31548</th>\n",
       "      <td>f1857fce43faa8d782e1c16f2f952b6f13f47ccc</td>\n",
       "      <td>Special Issue on Deep Structured Learning for ...</td>\n",
       "      <td>2021</td>\n",
       "      <td>https://www.semanticscholar.org/paper/f1857fce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31549</th>\n",
       "      <td>d4ea13d8a219d73b5d5458c79acabffe40ea99d9</td>\n",
       "      <td>Special issue on applications and techniques i...</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://www.semanticscholar.org/paper/d4ea13d8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31550</th>\n",
       "      <td>da5adf9cc8cb19dfaa22685ee9d2af65c0301e98</td>\n",
       "      <td>24.4 MOVING SPEECH TECHNOLOGY METHODS OUT OF T...</td>\n",
       "      <td>2019</td>\n",
       "      <td>https://www.semanticscholar.org/paper/da5adf9c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31551</th>\n",
       "      <td>2291ada21f869e22d01f177740c972b19ab726af</td>\n",
       "      <td>Analytic Fusion for Essential Indicators of th...</td>\n",
       "      <td>2019</td>\n",
       "      <td>https://www.semanticscholar.org/paper/2291ada2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31552 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             id  \\\n",
       "0      2c206603bbc8bea9ad2d859719421ca99a23c77a   \n",
       "1      38c14553dbf3a308ada57dbea88aa890c6a2defb   \n",
       "2      d0f4407d7cbf5bb607f99e0a30fc7e311b486b60   \n",
       "3      00d124fab3e4895130f3563bb7e03b18b646a682   \n",
       "4      08b6f8cdaaa3d090f0ffab2c41fc1261a24d7b76   \n",
       "...                                         ...   \n",
       "31547  6b84ba4f4a070de01b3638f76f62cf708aa776fa   \n",
       "31548  f1857fce43faa8d782e1c16f2f952b6f13f47ccc   \n",
       "31549  d4ea13d8a219d73b5d5458c79acabffe40ea99d9   \n",
       "31550  da5adf9cc8cb19dfaa22685ee9d2af65c0301e98   \n",
       "31551  2291ada21f869e22d01f177740c972b19ab726af   \n",
       "\n",
       "                                                   title  year  \\\n",
       "0      SwinTextSpotter: Scene Text Spotting via Bette...  2022   \n",
       "1      Few Could Be Better Than All: Feature Sampling...  2022   \n",
       "2      Towards End-to-End Unified Scene Text Detectio...  2022   \n",
       "3      Kernel Proposal Network for Arbitrary Shape Te...  2022   \n",
       "4      Fourier Contour Embedding for Arbitrary-Shaped...  2021   \n",
       "...                                                  ...   ...   \n",
       "31547  Editorial: Designing a Protocol Adopting an Ar...  2021   \n",
       "31548  Special Issue on Deep Structured Learning for ...  2021   \n",
       "31549  Special issue on applications and techniques i...  2020   \n",
       "31550  24.4 MOVING SPEECH TECHNOLOGY METHODS OUT OF T...  2019   \n",
       "31551  Analytic Fusion for Essential Indicators of th...  2019   \n",
       "\n",
       "                                                     url  \n",
       "0      https://www.semanticscholar.org/paper/2c206603...  \n",
       "1      https://www.semanticscholar.org/paper/38c14553...  \n",
       "2      https://www.semanticscholar.org/paper/d0f4407d...  \n",
       "3      https://www.semanticscholar.org/paper/00d124fa...  \n",
       "4      https://www.semanticscholar.org/paper/08b6f8cd...  \n",
       "...                                                  ...  \n",
       "31547  https://www.semanticscholar.org/paper/6b84ba4f...  \n",
       "31548  https://www.semanticscholar.org/paper/f1857fce...  \n",
       "31549  https://www.semanticscholar.org/paper/d4ea13d8...  \n",
       "31550  https://www.semanticscholar.org/paper/da5adf9c...  \n",
       "31551  https://www.semanticscholar.org/paper/2291ada2...  \n",
       "\n",
       "[31552 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
